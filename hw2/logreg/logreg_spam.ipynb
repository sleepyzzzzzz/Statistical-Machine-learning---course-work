{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from sklearn import linear_model\n",
    "#import sklearn.cross_validation\n",
    "from sklearn import model_selection\n",
    "#from sklearn.cross_validation import KFold\n",
    "import scipy.io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda = 0.100\n",
      "Coefficients = [-4.86009525] [[-2.74747273e-02 -2.25136402e-01  1.21907182e-01  2.27522248e+00\n",
      "   2.70520048e-01  2.32897315e-01  9.27944257e-01  2.95208723e-01\n",
      "   1.62385572e-01  6.78970232e-02 -8.31678264e-02 -1.60294620e-01\n",
      "  -4.73224775e-02  1.09256359e-02  1.88459779e-01  8.20164550e-01\n",
      "   5.10056275e-01  3.99249443e-02  2.67722637e-01  3.47759627e-01\n",
      "   2.60466272e-01  3.63354351e-01  7.24506472e-01  1.96760767e-01\n",
      "  -3.15898998e+00 -4.03875376e-01 -1.25626458e+01 -6.05923619e-02\n",
      "  -1.55586355e+00 -5.63614779e-02 -3.20084077e-02  4.07346185e-01\n",
      "  -3.68461579e-01 -1.39284860e+00 -5.81733635e-01  4.43810619e-01\n",
      "   4.21962305e-02 -1.56968921e-01 -4.55665222e-01 -1.02481037e-01\n",
      "  -3.52682718e+00 -1.73901534e+00 -4.36519687e-01 -1.06148809e+00\n",
      "  -9.18491783e-01 -1.75143034e+00 -1.67498490e-01 -9.53333133e-01\n",
      "  -3.65594020e-01 -1.36280389e-01 -6.58843258e-02  2.06700357e-01\n",
      "   1.70664664e+00  1.22614438e+00 -3.33799718e-01  1.55454544e+00\n",
      "   3.69925787e-01]]\n",
      "Accuracy on set aside test set for std = 0.9290\n",
      "best_lambda = 0.600\n",
      "Coefficients = [-4.60944211] [[-0.45145778 -0.28466464 -0.06327059  0.68295877  1.21053254  0.91505153\n",
      "   2.83046478  1.43678917  0.24145522  0.35776559 -0.38644157 -0.48143308\n",
      "  -0.69586995  0.37456822  0.64885547  1.53956331  1.38117898  0.0719749\n",
      "   0.37642779  0.63502193  0.52274199  0.38563856  2.00139368  1.50817041\n",
      "  -3.14061183 -0.66616276 -4.90648702 -0.03259691 -1.28886401 -0.15745776\n",
      "  -0.63900572 -0.30230277 -1.00989918 -0.42569045 -1.08722132  1.28434785\n",
      "  -0.90558623 -0.3528603  -1.12971552 -0.62591003 -1.4033734  -2.44124084\n",
      "  -1.55654051 -1.94777914 -1.13114573 -2.7999154  -0.75122197 -2.11602976\n",
      "  -1.68511534 -0.66773916 -0.69125858  2.06912519  4.21977464  0.76308651\n",
      "   0.70345789  0.17008401  0.4301883 ]]\n",
      "Accuracy on set aside test set for logt = 0.9434\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-1.82566816] [[-1.78313887e-01 -1.60085506e-01 -3.73001110e-01  2.36358803e-01\n",
      "   9.46367588e-01  1.59613651e-01  2.03690641e+00  7.62617294e-01\n",
      "   1.81159712e-01  3.12388353e-01 -2.60352275e-01 -4.14115142e-01\n",
      "  -8.66097179e-01  2.36335390e-01  4.75358415e-01  1.43030139e+00\n",
      "   8.23118667e-01 -6.18540143e-02  2.39595773e-01  4.50237962e-01\n",
      "   7.24354332e-01  1.06352180e+00  8.70212070e-01  1.30340906e+00\n",
      "  -2.20348245e+00 -4.57176451e-01 -3.39242058e+00  5.45347540e-01\n",
      "  -5.60588209e-01 -1.85244388e-01 -8.05548612e-01 -4.84223733e-01\n",
      "  -6.36751901e-01 -8.68074833e-02 -6.31860077e-01  3.04485691e-01\n",
      "  -1.03756760e+00  4.18380738e-01 -7.08628405e-01 -2.18361509e-01\n",
      "  -1.07385026e+00 -1.74862153e+00 -6.95533233e-01 -1.43004581e+00\n",
      "  -7.40200632e-01 -2.11078935e+00 -9.46977030e-02 -1.24285032e+00\n",
      "  -2.91376072e-01  1.90460650e-01 -1.65731167e-01  1.19345678e+00\n",
      "   1.42337675e+00  6.04361397e-02  7.86190059e-04  7.86190059e-04\n",
      "   7.86190059e-04]]\n",
      "Accuracy on set aside test set for bin = 0.9284\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda = 4.600\n",
      "Coefficients = [-1.58306524] [[-0.01062559 -0.15864481  0.12267765  0.20854339  0.24908149  0.1768191\n",
      "   0.91064519  0.28988669  0.13940024  0.04856513 -0.02285647 -0.1397994\n",
      "  -0.00708624  0.00922048  0.15415856  0.75696273  0.46014798  0.07055743\n",
      "   0.254014    0.19614565  0.24314457  0.34670189  0.72764335  0.23451713\n",
      "  -2.33623357 -0.35708115 -3.14081015 -0.01137601 -0.36970765  0.\n",
      "   0.          0.         -0.32787564  0.         -0.06133501  0.24273336\n",
      "   0.         -0.11597723 -0.31120765 -0.04401239 -0.23862613 -0.79322082\n",
      "  -0.19061005 -0.56323238 -0.73353872 -1.17908767 -0.0854329  -0.51287311\n",
      "  -0.25649843 -0.13385162 -0.05685047  0.21848107  1.64863375  0.22192818\n",
      "   0.          0.64757991  0.33270703]]\n",
      "Accuracy on set aside test set for std = 0.9219\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-4.46259225] [[-0.34342569 -0.09574608  0.          0.12943372  1.18453444  0.69050436\n",
      "   2.91335439  1.37685143  0.          0.29525576  0.         -0.48065882\n",
      "  -0.32791846  0.10718788  0.          1.49526021  1.34905863  0.\n",
      "   0.35492452  0.19664355  0.49433079  0.34778475  1.7846422   1.32954624\n",
      "  -3.49780861 -0.26970803 -7.49363789  0.         -0.41758247  0.\n",
      "   0.          0.         -0.79146063  0.         -0.23883657  0.87188378\n",
      "  -0.7743498   0.         -0.88298301  0.         -0.30384296 -2.35518828\n",
      "  -0.69475843 -1.66136236 -1.13796061 -2.98273742  0.         -1.90138656\n",
      "  -1.24515778 -0.30342169  0.          2.01462895  5.36676757  0.\n",
      "   0.63612903  0.20223987  0.387967  ]]\n",
      "Accuracy on set aside test set for logt = 0.9440\n",
      "best_lambda = 3.600\n",
      "Coefficients = [-0.01151386] [[ 0.          0.         -0.19327912  0.          0.86606808  0.\n",
      "   2.02975836  0.632517    0.0267303   0.21304554  0.         -0.42093053\n",
      "  -0.68112299  0.          0.          1.31585192  0.76570026  0.\n",
      "   0.10361539  0.12259829  0.63768444  0.73010782  0.62190751  1.18368901\n",
      "  -2.42360664 -0.12656738 -3.73152838  0.          0.          0.\n",
      "   0.          0.         -0.28768672  0.         -0.21903622  0.\n",
      "  -1.0155118   0.         -0.40479995  0.         -0.1151505  -1.6945344\n",
      "  -0.03916639 -1.10966633 -0.68755652 -2.21931894  0.         -1.02591074\n",
      "  -0.12495042  0.07349599  0.          1.15131871  1.4998481   0.\n",
      "  -0.73961446 -0.51466787 -0.39978277]]\n",
      "Accuracy on set aside test set for bin = 0.9258\n"
     ]
    }
   ],
   "source": [
    "# No modifications in this cell\n",
    "# complete the functions in utils.py; then run the cell\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,typea,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print(\"best_lambda = %.3f\" %best_lambda)\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True,max_iter=1000)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True,max_iter=1000)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print(\"Coefficients = %s\" %lreg.intercept_,lreg.coef_)\n",
    "    predy = lreg.predict(Xt)\n",
    "    print(\"Accuracy on set aside test set for %s = %.4f\" %(typea, np.mean(predy==ytest)))\n",
    "\n",
    "print(\"L2 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print(\"L1 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
