{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1: Part 2\n",
    "## Implementing regularized linear regression \n",
    "In this part, you will implement regularized linear regression and use it to\n",
    "study models with different bias-variance properties. \n",
    "\n",
    "This notebook contains code that helps you get started on \n",
    "linear regression with regularization. \n",
    "You will need to complete functions in\n",
    "**reg_linear_regressor.py** and **utils.py**.\n",
    "Modify this notebook in places marked by **TODO:**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized linear regression: an example\n",
    "In this problem, you will implement regularized linear regression\n",
    "to predict the amount of water flowing out of a dam using the change\n",
    "of water level in a reservoir. We will begin by visualizing the dataset containing historical records on the\n",
    "change in the water level $x$, and the amount of water $y$, flowing out of the dam.\n",
    "This dataset is divided into three parts:\n",
    "- A training set that you will use to learn the model:  X,  y.\n",
    "- A validation set for determining the regularization parameter: Xval, yval.\n",
    "- A test set for evaluating the performance of your model:  Xtest, ytest. These are unseen examples that were not used during the training of the model.\n",
    "\n",
    "Run the cell below and it  will plot the training data as shown in Figure 6 in your assignment handout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import plot_utils\n",
    "from reg_linear_regressor_multi import RegularizedLinearReg_SquaredLoss\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "########################################################################\n",
    "## =========== Part 1: Loading and Visualizing Data ===================#\n",
    "########################################################################\n",
    "# Load Training Data\n",
    "\n",
    "print('Loading and Visualizing Data ...')\n",
    "\n",
    "X, y, Xtest, ytest, Xval, yval = utils.load_mat('ex2data1.mat')\n",
    "\n",
    "# Plot training data\n",
    "\n",
    "plot_utils.plot_data(X,y,'Change in water level (x)','Water flowing out of the dam (y)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Linear Regression cost function and gradient (vectorized)\n",
    "You should now implement the loss function and gradient of the\n",
    "loss function for regularized linear regression in **reg_linear_regression_multi.py**. Then run the cell below.\n",
    "Regularized linear regression has the following cost function:\n",
    "$$J(\\theta) = \\frac{1}{2m} \\left( \\sum_{i=1}^{m} {( y^{(i)} - h_\\theta(x^{(i)})}^2\\right) + \\frac{\\lambda}{2m}\\left( \\sum_{j=1}^{n} {\\theta_j}^2 \\right) $$\n",
    "where $\\lambda$ is a regularization parameter which controls the degree of regularization\n",
    "(thus, help preventing overfitting). The regularization term puts\n",
    "a penalty on the overall cost $J(\\theta)$. As the magnitudes of the model parameters $\\theta_j$ increase, the penalty increases as well. Note that you should not regularize the $\\theta_0$ term. You should now complete the code for the method loss in the class Reg_LinearRegression_SquaredLoss in the file reg_linear_regressor_multi.py to calculate $J(\\theta)$. Vectorize your code and avoid writing for loops.\n",
    "\n",
    "Correspondingly, the partial derivative of the regularized linear regression  cost function\n",
    "with respect to  $\\theta_j$ is defined as:\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_0} & = & \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}){x_j}^{(i)} \\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} & = & \\left(\\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)} ){x_j}^{(i)}\\right) + \\frac{\\lambda}{m}{\\theta_j} \\; \\; \\; \\mbox{ for }j \\geq 1\\\\\n",
    "\\end{eqnarray*}\n",
    "You should now complete the code for the method grad_loss in the class {Reg_LinearRegression_SquaredLoss in the file reg_linear_regressor_multi.py}\n",
    "to  calculate the gradient, returning\n",
    "it in the variable grad. \n",
    "\n",
    "Then evaluate the cell below. It runs the train method in  reg_linear_regressor_multi.py to compute the optimal value\n",
    "of $\\theta$. This training function uses scipy's fmin_bfgs to optimize the cost function.\n",
    "Here we have set the regularization parameter $\\lambda$ to zero. \n",
    "\n",
    "The best fit line plotted by the script  tells us that the model is\n",
    "not a good fit to the data because the data is non-linear. While\n",
    "visualizing the best fit as shown is one possible way to debug your learning\n",
    "algorithm, it is not always easy to visualize the data and model. In the next\n",
    "cell, you will implement a function to generate learning curves that can\n",
    "help you debug your learning algorithm even if it is not easy to visualize the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a column of ones to matrix X\n",
    "\n",
    "XX = np.vstack([np.ones((X.shape[0],)),X]).T\n",
    "\n",
    "#  Train linear regression with lambda = 0\n",
    "\n",
    "reglinear_reg1 = RegularizedLinearReg_SquaredLoss()\n",
    "theta_opt0 = reglinear_reg1.train(XX,y,reg=0.0,num_iters=1000)\n",
    "print('Theta at lambda = 0 is %s' % (theta_opt0))\n",
    "\n",
    "# plot fit over data and show it (or save it in fig7.pdf)\n",
    "plot_utils.plot_data(X,y,'Change in water level (x)','Water flowing out of the dam (y)')\n",
    "plt.plot(X,np.dot(XX,theta_opt0),'g-',linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve for linear regression\n",
    "An important concept in machine learning is the bias-variance tradeoff. Models\n",
    "with high bias are not complex enough for the data and tend to underfit,\n",
    "while models with high variance overfit  the training data.\n",
    "Here you will plot training and test errors on a\n",
    "learning curve to diagnose bias-variance problems.\n",
    "\n",
    "A  learning curve plots\n",
    "training and cross validation error as a function of training set size. You will complete the\n",
    "function  learning_curve in utils.py so that it returns a vector of errors for the\n",
    "training set and  validation set.\n",
    "To obtain different training set sizes,\n",
    "use different subsets of the original training set X. Specifically, for\n",
    "a training set size of $i$, you should use the first $i$ examples.\n",
    "\n",
    "You can use the train function to find the parameter $\\theta$. Note\n",
    "that the regularization $\\lambda$  is passed as a parameter to the learning_curve function.\n",
    "After learning the $\\theta$ parameter, you should compute the error on the training\n",
    "and validation sets. Recall that the training error for a dataset is\n",
    "defined as:\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\left( \\sum_{i=1}^{m} {( y^{(i)} - h_\\theta(x^{(i)})}^2\\right)  $$\n",
    "\n",
    "\n",
    "In particular, note that the training error does not include the regularization\n",
    "term. One way to compute the training error is to use your existing\n",
    "cost function and set the regularization parameter reg to 0 only when using it to compute the training error\n",
    "and validation error. When you are computing the training set error,\n",
    "make sure you compute it on the training subset\n",
    "instead of the entire training set. However, for the validation error,\n",
    "you should compute it over the entire validation set. You should store\n",
    "the computed errors in the vectors error_train and error_val.\n",
    "When you are finished, the cell below will print the learning curves and produce\n",
    "a plot similar to Figure 8 in the assignment handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1.0\n",
    "XXval = np.vstack([np.ones((Xval.shape[0],)),Xval]).T\n",
    "\n",
    "# implement the learning_curve function in utils.py\n",
    "# this script will run your function and show the learning curve\n",
    "\n",
    "error_train, error_val = utils.learning_curve(XX,y,XXval,yval,reg)\n",
    "plot_utils.plot_learning_curve(error_train, error_val,reg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression: expanding the basis functions\n",
    "The problem with our linear model was that it was too simple for the data\n",
    "and resulted in underfitting (high bias). In this problem, you will address this issue by adding more features. In particular, you will consider hypotheses of the form\n",
    "$$ h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\ldots + \\theta_p x^p $$\n",
    "This is still a linear model from the point of view of the parameter space. We have augmented the features with powers of $x$.\n",
    "Code in the cell below builds these features using sklearn's preprocessing module. \n",
    "\n",
    "We use a polynomial of degree 6.\n",
    "It turns out that if we run the training directly on the projected data,  it will\n",
    "not work well as the features would be badly scaled (e.g., an example with\n",
    "$x = 40$ will now have a feature $x^6 = 40^6 = 4.1 \\times 10^{9}$). Therefore, you will\n",
    "need to use feature normalization.\n",
    "Before learning the parameter $\\theta$ for the polynomial regression, the script in the cell below will\n",
    "first call the **feature_normalize** function you wrote earlier. It will normalize the features of the training set,\n",
    "storing the mu, sigma parameters separately. It will project the validation and test sets too, but normalize them using the same mu and sigma parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import feature_normalize\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Map X onto polynomial features and normalize\n",
    "# We will consider a 6th order polynomial fit for the data\n",
    "\n",
    "p = 6\n",
    "poly = sklearn.preprocessing.PolynomialFeatures(degree=p,include_bias=False)\n",
    "X_poly = poly.fit_transform(np.reshape(X,(len(X),1)))\n",
    "X_poly, mu, sigma = utils.feature_normalize(X_poly)\n",
    "\n",
    "# add a column of ones to X_poly\n",
    "\n",
    "XX_poly = np.vstack([np.ones((X_poly.shape[0],)),X_poly.T]).T\n",
    "\n",
    "# map Xtest and Xval into the same polynomial features\n",
    "\n",
    "X_poly_test = poly.fit_transform(np.reshape(Xtest,(len(Xtest),1)))\n",
    "X_poly_val = poly.fit_transform(np.reshape(Xval,(len(Xval),1)))\n",
    "\n",
    "# normalize these two sets with the same mu and sigma\n",
    "\n",
    "X_poly_test = (X_poly_test - mu) / sigma\n",
    "X_poly_val = (X_poly_val - mu) / sigma\n",
    "\n",
    "# add a column of ones to both X_poly_test and X_poly_val\n",
    "XX_poly_test = np.vstack([np.ones((X_poly_test.shape[0],)),X_poly_test.T]).T\n",
    "XX_poly_val = np.vstack([np.ones((X_poly_val.shape[0],)),X_poly_val.T]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves for polynomial regression\n",
    "The cell below trains a linear model on the transformed data. After learning $\\theta$, you should see two plots \n",
    "generated for polynomial regression with $\\lambda= 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 0.0\n",
    "reglinear_reg2 = RegularizedLinearReg_SquaredLoss()\n",
    "theta_opt1 = reglinear_reg1.train(XX_poly,y,reg=reg,num_iters=10000)\n",
    "print('Theta at lambda = 0 is %s' % (theta_opt1))\n",
    "\n",
    "\n",
    "# plot data and training fit for the 6th order polynomial \n",
    "\n",
    "plot_utils.plot_fit(X,y,np.min(X),np.max(X),mu,sigma,theta_opt1,p,'Change in water level (x)','Water flowing out of dam (y)','Polynomial Regression fit with lambda = 0 and polynomial features of degree = ' + str(p))\n",
    "plt.show()\n",
    "\n",
    "# plot learning curve for data (6th order polynomail basis function) \n",
    "\n",
    "error_train,error_val = utils.learning_curve(XX_poly,y,XX_poly_val,yval,reg)\n",
    "plot_utils.plot_learning_curve(error_train,error_val,reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the regularization parameter\n",
    "You will now explore how the regularization parameter\n",
    "affects the bias-variance of regularized polynomial regression. You should\n",
    "now modify the  lambda parameter in the cell above and try $\\lambda = 1, 10, 100$. For\n",
    "each of these values, the script will generate a polynomial fit to the data\n",
    "and also a learning curve. Submit two plots for each value of lambda: the fit as well as the learning curve. Comment on the impact of the choice of lambda on the quality of the learned model in your **writeup.pdf**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating test error on the best model\n",
    "To get a better indication of a model's performance in the real\n",
    "world, it is important to evaluate the final model on a test set that was\n",
    "not used in any part of training (that is, it was neither used to select the regularization parameter, nor to learn the model parameters).\n",
    "Calculate the error of the best model that you found with the previous analysis\n",
    "and report it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code for computing test error on the best model (model with the best lambda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting $\\lambda$ using a validation set\n",
    "You will implement an automated method to select the $\\lambda$ parameter. Concretely, you will use a validation set to evaluate how good each $\\lambda$ value is. After selecting the best $\\lambda$ value using the \n",
    "validation set, we can then evaluate the model on the test set to estimate\n",
    "how well the model will perform on actual unseen data.\n",
    "**Complete the function validation_curve.m in utils.py**. Specifically,\n",
    "you should should use the train method on an instance of the class Reg_Linear_Regressor to train the model using\n",
    "different values of $\\lambda$ and to compute the training error and  validation error.\n",
    "You should try $\\lambda$ in the following range: \\{0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\\}.\n",
    "\n",
    "After you have completed the code, run the cell below to plot a validation curve of $\\lambda$ versus the error. This plot  allows you select\n",
    "which $\\lambda$ value to use. Due to randomness\n",
    "in the training and validation splits of the dataset, the cross validation error\n",
    "can sometimes be lower than the training error. Submit a pdf version of this plot in **writeup.pdf**. Comment on the best choice of $\\lambda$ for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement the validation_curve function in utils.py\n",
    "# this function helps in determining the best lambda using a\n",
    "# a validation set\n",
    "# The code will now run your function and plot the figure \n",
    "\n",
    "reg_vec, error_train, error_val = utils.validation_curve(XX_poly,y,XX_poly_val,yval)\n",
    "plot_utils.plot_lambda_selection(reg_vec,error_train,error_val)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting learning curves with randomly selected examples \n",
    "In practice, especially for small training sets, when you plot learning curves\n",
    "to debug your algorithms, it is often helpful to average across multiple sets\n",
    "of randomly selected examples to determine the training error and \n",
    "validation error.\n",
    "Concretely, to determine the training error and cross validation error for\n",
    "$i$ examples, you should first randomly select $i$ examples from the training set\n",
    "and $i$ examples from the  validation set. You will then learn the model parameters using the randomly chosen training set and evaluate the parameters on the randomly chosen training set and validation set. The above\n",
    "steps should then be repeated multiple times (say 50) and the averaged error\n",
    "should be used to determine the training error and cross validation error for\n",
    "$i$ examples.\n",
    "Implement the above\n",
    "strategy for computing the learning curves. Complete the  function\n",
    "**learning_curve_averaged** in  **utils.py** to generate compute and generate this plot. Then evaluate the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement the averaged learning curve function in utils.py\n",
    "# The script runs your function, plots the curves and saves it in fig11.pdf\n",
    "\n",
    "reg = 1.0\n",
    "error_train,error_val = utils.averaged_learning_curve(XX_poly,y,XX_poly_val,yval,reg)\n",
    "plot_utils.plot_learning_curve(error_train,error_val,reg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the learned parameters of ridge regression and lasso regression\n",
    "With different regularization methods, the learned parameters behaves differently. In this section you are going to compare the parameters learned from the ridge regression and the lasso regression. Remember that the loss and subgradient of the lasso regression has the form:\n",
    "$$\\begin{eqnarray*}\n",
    "J(\\theta) & = & \\frac{1}{2m} \\left( \\sum_{i=1}^{m} {( y^{(i)} - h_\\theta(x^{(i)})}^2\\right) + \\frac{\\lambda}{m} \\sum_{j=1}^{n} |{\\theta_j}|\\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_0} & = & \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}){x_j}^{(i)} \\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} & = & \\left(\\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)} ){x_j}^{(i)}\\right) + \\frac{\\lambda}{m}{\\mbox{sign}(\\theta_j)} \\; \\; \\; \\mbox{ for }j \\geq 1\\\\\n",
    "\\end{eqnarray*}$$First complete the **loss** and **grad_loss** function in the **LassoReg_SquaredLoss** class in **reg_linear_regressor_multi.py**, then train the parameters using **XX_poly**. Use $\\lambda = 0.5$. Plot the magnitude of entries of $\\theta$ trained from each method in descending order, and report what you see in **writeup.pdf**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reg_linear_regressor_multi import LassoLinearReg_SquaredLoss\n",
    "reg = 0.5\n",
    "\n",
    "# Create the two regressors.\n",
    "\n",
    "ridge_regressor = RegularizedLinearReg_SquaredLoss()\n",
    "lasso_regressor = LassoLinearReg_SquaredLoss()\n",
    "\n",
    "# Train them with the polynomial expansion.\n",
    "\n",
    "ridge_theta = np.abs(ridge_regressor.train(XX_poly,y,reg=reg,num_iters=10000))[1:]\n",
    "lasso_theta = np.abs(lasso_regressor.train(XX_poly,y,reg=reg,num_iters=10000))[1:]\n",
    "\n",
    "# Sort the absolute values of the parameters.\n",
    "\n",
    "sorted_ridge_theta = -np.sort(-ridge_theta)\n",
    "sorted_lasso_theta = -np.sort(-lasso_theta)\n",
    "\n",
    "# Plot the parameters.\n",
    "\n",
    "num_params = len(ridge_theta)\n",
    "plt.plot(range(num_params), sorted_ridge_theta, label='ridge params')\n",
    "plt.plot(range(num_params), sorted_lasso_theta, label='lasso params')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Building regularized models for Boston data set (10 points)\n",
    "-- completely optional\n",
    "\n",
    "Perform a bias variance analysis of the Boston housing data set with the thirteen predictors, following the steps on the simple data set above. Use sklearn's  built-in functions to split the data into training, validation and test sets. What is the lowest achievable error on the test set with $\\lambda = 0$? Select the best value for $\\lambda$ and report the test set error with the best $\\lambda$. Use the technique of adding features to extend each column of the Boston data set with powers of the values in the column. Repeat the bias-variance analysis with quadratic and cubic features. What is the test set error with quadratic features with the best $\\lambda$ chosen with the validation set? What is the test set error with cubic features with the best $\\lambda$ chosen with the validation set? Put your analysis code in a separate Python script or notebook called bostonexpt.py or bostonexpt.ipynb. Present your results analytically with plots to support your findings. Discuss the impact of regularization for building good models for the Boston housing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: your Boston code here or in a separate notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
